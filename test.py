from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import os, json
from supabase import create_client, Client
from dotenv import load_dotenv
from langgraph.graph import StateGraph
from typing import TypedDict
import httpx

# ----------------------------
# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø­ÛŒØ·
# ----------------------------
load_dotenv()
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

if not all([GITHUB_TOKEN, SUPABASE_URL, SUPABASE_KEY]):
    raise ValueError("âŒ Missing environment variables!")

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# ----------------------------
# Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ø´
# ----------------------------
knowledge_dir = "knowledge"
knowledge_data = {}
if not os.path.exists(knowledge_dir):
    os.makedirs(knowledge_dir)

for fname in os.listdir(knowledge_dir):
    if fname.endswith(".json"):
        topic = fname.replace(".json", "")
        with open(os.path.join(knowledge_dir, fname), "r", encoding="utf-8") as f:
            knowledge_data[topic] = json.load(f)

print("âœ… Loaded topics:", list(knowledge_data.keys()))

# ----------------------------
# FastAPI setup
# ----------------------------
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ----------------------------
# ØªØ¹Ø±ÛŒÙ State
# ----------------------------
class QAState(TypedDict, total=False):
    question: str
    answer: str


# ----------------------------
# ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ API Ú¯ÛŒØªÙ‡Ø§Ø¨
# ----------------------------
async def github_llm(prompt: str) -> str:
    headers = {"Authorization": f"Bearer {GITHUB_TOKEN}", "Content-Type": "application/json"}
    payload = {
        "model": "openai/gpt-4o-mini",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.3,
    }
    try:
        async with httpx.AsyncClient(timeout=20) as client:
            response = await client.post(
                "https://models.github.ai/inference/chat/completions",
                headers=headers,
                json=payload,
            )
        response.raise_for_status()  # Raise error if not 200
        data = response.json()
        return data["choices"][0]["message"]["content"].strip()
    except Exception as e:
        print(f"âš ï¸ GitHub API error: {e}")
        return "Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ù…Ø´Ú©Ù„ÛŒ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø§Ø³Ø® Ù¾ÛŒØ´ Ø¢Ù…Ø¯."


# ----------------------------
# Node Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø®â€ŒØ¯Ù‡ÛŒ
# ----------------------------
async def responder(state: QAState) -> dict:
    question = state["question"]
    combined_info = json.dumps(knowledge_data, ensure_ascii=False)  # ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§

    prompt = f"""
    ØªÙˆ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´Ù…Ù†Ø¯ ÙØ§Ø±Ø³ÛŒâ€ŒØ²Ø¨Ø§Ù† Ù‡Ø³ØªÛŒ.
    ÙˆØ¸ÛŒÙÙ‡â€ŒØ§Øª Ø§ÛŒÙ†Ù‡ Ú©Ù‡ ØªØ´Ø®ÛŒØµ Ø¨Ø¯ÛŒ Ø³ÙˆØ§Ù„ Ú©Ø§Ø±Ø¨Ø± Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ú©Ø¯ÙˆÙ… Ø­ÙˆØ²Ù‡ Ø§Ø³Øª (Ù…Ø«Ù„Ø§Ù‹ Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯,ÙØ±ÙˆØ´ Ù…ØªØ±ÛŒØŒ Ù„Ø¨Ø§Ø³ØŒ Ø¨ÛŒÙ…Ù‡ØŒ Ù…Ø§Ù„ÛŒØ§Øª ÛŒØ§ Ø®ÙˆØ¯Ø±Ùˆ)
    Ùˆ ÙÙ‚Ø· Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‡Ù…Ø§Ù† Ø­ÙˆØ²Ù‡ Ù¾Ø§Ø³Ø® Ø¨Ø¯Ù‡.

    Ø§Ú¯Ø± Ø³ÙˆØ§Ù„ Ù…Ø¨Ù‡Ù… Ø¨ÙˆØ¯ ÛŒØ§ Ù…Ø´Ø®Øµ Ù†Ø¨ÙˆØ¯ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ú©Ø¯ÙˆÙ… Ù…ÙˆØ¶ÙˆØ¹Ù‡ØŒ Ù…Ø­ØªØ±Ù…Ø§Ù†Ù‡ Ø¨Ù¾Ø±Ø³ Ø¨Ø±Ø§ÛŒ Ø´ÙØ§Ùâ€ŒØ³Ø§Ø²ÛŒ.

    Ù¾Ø§Ø³Ø® Ø¨Ø§ÛŒØ¯:
    - Ú©ÙˆØªØ§Ù‡ØŒ Ø³Ø§Ø¯Ù‡ Ùˆ Ù…Ø­Ø§ÙˆØ±Ù‡â€ŒØ§ÛŒ Ø¨Ø§Ø´Ù‡
    - Ø§Ø² Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø±Ø³Øª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†Ù‡ØŒ Ù†Ù‡ Ø­Ø¯Ø³ Ø²Ø¯Ù†
    - ÙÙ‚Ø· Ø¨Ù‡ Ù…ÙˆØ¶ÙˆØ¹ Ù…Ø±ØªØ¨Ø· Ø¬ÙˆØ§Ø¨ Ø¨Ø¯Ù‡

    ğŸ”¸ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙˆ:
    {combined_info}

    ğŸ”¸ Ø³ÙˆØ§Ù„ Ú©Ø§Ø±Ø¨Ø±:
    {question}

    Ù¾Ø§Ø³Ø® Ø±Ø§ Ø®ÛŒÙ„ÛŒ Ø®Ù„Ø§ØµÙ‡ØŒ Ø·Ø¨ÛŒØ¹ÛŒ Ùˆ Ù‚Ø§Ø¨Ù„ ÙÙ‡Ù… Ø¨Ø¯Ù‡.
    """
    answer = await github_llm(prompt)
    return {"answer": answer}


# ----------------------------
# Ø³Ø§Ø®Øª Ú¯Ø±Ø§Ù
# ----------------------------
graph = StateGraph(QAState)
graph.add_node("responder", responder)
graph.set_entry_point("responder")
graph.set_finish_point("responder")

# Compile the graph to make it runnable
graph = graph.compile()


# ----------------------------
# API endpoint
# ----------------------------
@app.post("/ask")
async def ask_question(request: Request):
    body = await request.json()
    question = body.get("question", "").strip()
    if not question:
        return JSONResponse(status_code=400, content={"error": "Question field is required."})

    # Ø§Ø¬Ø±Ø§ÛŒ Ú¯Ø±Ø§Ù Ø¨Ù‡ ØµÙˆØ±Øª async
    init_state = QAState({"question": question})
    final_state = await graph.ainvoke(init_state)
    answer = final_state.get("answer", "Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ù†ØªÙˆÙ†Ø³ØªÙ… Ù¾Ø§Ø³Ø® Ø¨Ø¯Ù….")

    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Supabase
    try:
        supabase.table("chat_logs").insert({
            "question": question,
            "answer": answer
        }).execute()
    except Exception as db_err:
        print("âš ï¸ DB save error:", db_err)

    return JSONResponse(content={"answer": answer})